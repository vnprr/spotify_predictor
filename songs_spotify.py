# -*- coding: utf-8 -*-
"""songs_spotify.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QNINcXFAuCM_rcXzSm6np7ZcfkbE4_Ih
"""

import matplotlib.pyplot as plt
import nltk
import os
import pandas as pd
import seaborn as sns
import string
from keras.layers import Dense
from keras.models import Sequential
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.linear_model import RidgeCV
from sklearn.metrics import r2_score
from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn.preprocessing import OrdinalEncoder, StandardScaler
from sklearn.svm import SVR
from tqdm import tqdm

tqdm.pandas()
nltk.download('punkt')
nltk.download('stopwords')

os.chdir("/content/drive/MyDrive/Programowanie/SpotifyPredicterRefactored")

ARTISTS_PATH = "data/artists_mb.csv.gz"
USECOLS = ["artist_mb", "country_mb", "ambiguous_artist"]

SONGS_PATH="data/spotify_songs_processed.csv.gz"

NUMERIC_COLUMNS = [
    'track_album_release_year',
    'track_album_release_month',
    'danceability',
    'energy',
    'key',
    'loudness',
    'mode',
    'speechiness',
    'acousticness',
    'instrumentalness',
    'liveness',
    'valence',
    'tempo',
    'duration_ms'
]


try:
    import pycountry
except:
    os.system('pip install pycountry')
    import pycountry


try:
    from pandarallel import pandarallel
except ModuleNotFoundError:
    os.system('pip install pandarallel')
    from pandarallel import pandarallel


pandarallel.initialize(progress_bar=True)

"""Przygotowanie danych

## Artists last_fm
"""

def load_artists(artists_mb_path=ARTISTS_PATH, usecols=USECOLS, drop_ambiguous_artist=True):
    """Importowanie pliku z lastfm by wzbogacić zbiór Spotify songs

    """
    if os.path.exists(artists_mb_path):
      df = pd.read_csv(artists_mb_path, index_col=0)
    else:
      artists_path = artists_mb_path.replace("artists_mb", "artists")
      df = pd.read_csv(
          artists_path,
          usecols=usecols
      ).drop_duplicates()

      if drop_ambiguous_artist:
          df = df[
              df["ambiguous_artist"] == False
          ]
          df = df.drop(columns="ambiguous_artist")

      df = df.dropna()

      df["artist_mb"] = df["artist_mb"].parallel_apply(
          lambda x: normalize_text(x)
      )
      df.to_csv(artists_mb_path)

    return df

def normalize_text(text):
    """
      Take raw text as an input and normalizes it to enable 
      comparison with data from another source data frame.
    """
    # Tokenize the text
    # tokens = word_tokenize(text.lower())
    tokens = word_tokenize(text)

    # Remove punctuation
    tokens = [token for token in tokens if token not in string.punctuation]

    tokens = [token.lower() if (type(token) == str) else token for token in tokens]

    # Remove stop words
    stop_words = set(stopwords.words('english'))
    tokens = [token for token in tokens if token not in stop_words]

    # Join tokens back into text
    normalized_text = ' '.join(tokens)

    return normalized_text


"""## Spotify songs"""

def load_spotify_songs(file_path_processed=SONGS_PATH):
    if os.path.exists(file_path_processed):
      df = pd.read_csv(file_path_processed, index_col=0)
    else:
      file_path = file_path_processed.replace(
        "_processed", ""
        )
      df = pd.read_csv(file_path)

      # extract day, month and year from single column
      spotify_songs_date = df["track_album_release_date"].str.split(
          "-", expand=True
      )

      df["track_album_release_year"] = spotify_songs_date[0]
      df["track_album_release_month"] = spotify_songs_date[1]

      df = df.drop(columns=[
          "track_album_id",
          "track_id",
          "track_album_name",
          "playlist_id",
          "track_name",
          "track_album_release_date"
      ])

      df["playlist_name"] = df["playlist_name"].parallel_apply(
          lambda x: normalize_text(x)
      )

      df = df[
          ~df["track_artist"].isna()
      ]

      df["track_artist"] = df["track_artist"].parallel_apply(
          lambda x: normalize_text(x)
      )
      df.to_csv(file_path_processed)

    return df


def load_joined_songs(spotify_songs, artists, left_on="track_artist", right_on="artist_mb"):
    """##łączenie zbiorów

    """
    df = pd.merge(
        left=spotify_songs,
        right=artists,
        left_on=left_on,
        right_on=right_on,
        how="left"
    )

    df = df.drop(
        columns=[left_on, right_on]
    )

    df["track_album_release_year"] = df["track_album_release_year"].astype(int)
    df = df[df["track_album_release_year"] >= 2000]

    moth_mode = df["track_album_release_month"].mode()
    df["track_album_release_month"] = df[
        "track_album_release_month"
        ].fillna(moth_mode[0])
    df["track_album_release_month"].isna().sum()

    df["duration_ms"] = df["duration_ms"].clip(100000, 350000)

    df = df.dropna(subset=["track_popularity"])

    #suma czy są wartości czy nie ma w songs_joined
    assert not df["track_popularity"].isna().sum()

    df = df.dropna(subset=["country_mb"])

    country_names = [country.name for country in pycountry.countries]
    mask = df["country_mb"].isin(country_names)
    df = df[mask]

    return df


def get_Xy(input_df, numeric_columns=NUMERIC_COLUMNS):

    y = input_df.pop('track_popularity')

    # scale numeric columns
    input_df_numeric = input_df[numeric_columns]
    scaler = StandardScaler()
    input_df_numeric = scaler.fit_transform(input_df_numeric)
    input_df_numeric = pd.DataFrame(input_df_numeric, columns = numeric_columns)

    # encode categorcial columns
    other_columns = [col for col in input_df.columns if col not in numeric_columns]

    encoder = OrdinalEncoder() #enkodowanie zmiennych kategorycznych
    input_df_other = encoder.fit_transform(input_df[other_columns]) #przeprowadzamy transformacje
    input_df_other = pd.DataFrame(input_df_other, columns = other_columns)

    X = pd.concat([input_df_numeric, input_df_other], axis = 1)

    return X, y
